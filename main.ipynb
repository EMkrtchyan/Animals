{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 620362 (2.37 MB)\n",
      "Trainable params: 620362 (2.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  \n",
    "  Conv2D(32, (3, 3),activation='relu', input_shape=x_train.shape[1:]),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Conv2D(64, (3, 3),activation='relu'),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  \n",
    "  Conv2D(128, (3, 3),activation='relu'),\n",
    "  Flatten(),\n",
    "  \n",
    "  Dense(256, activation='relu'),\n",
    "  Dropout(0.5),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 21s 31ms/step - loss: 1.6216 - accuracy: 0.4058 - val_loss: 1.3269 - val_accuracy: 0.5262\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 20s 33ms/step - loss: 1.2709 - accuracy: 0.5482 - val_loss: 1.1230 - val_accuracy: 0.6061\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 1.1056 - accuracy: 0.6109 - val_loss: 1.0163 - val_accuracy: 0.6482\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.9892 - accuracy: 0.6538 - val_loss: 0.9620 - val_accuracy: 0.6651\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.9032 - accuracy: 0.6851 - val_loss: 0.8713 - val_accuracy: 0.6984\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 0.8256 - accuracy: 0.7120 - val_loss: 0.8400 - val_accuracy: 0.7069\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 20s 33ms/step - loss: 0.7655 - accuracy: 0.7314 - val_loss: 0.8054 - val_accuracy: 0.7229\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.7104 - accuracy: 0.7507 - val_loss: 0.8209 - val_accuracy: 0.7214\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.6588 - accuracy: 0.7693 - val_loss: 0.7961 - val_accuracy: 0.7274\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.6195 - accuracy: 0.7806 - val_loss: 0.8100 - val_accuracy: 0.7281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20d394c70d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,epochs = 10,batch_size = 64,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8209100365638733 / Test accuracy: 0.7192000150680542\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 digits: [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "first 3 predsictins: [6 9 9]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "my_new_model = load_model('model.keras')\n",
    "y_train_pr = np.argmax(my_new_model.predict(x_train[:3],verbose = 0),axis =1)\n",
    "\n",
    "print('first 3 digits:', y_train[:3])\n",
    "print('first 3 predsictins:', y_train_pr[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Սկզբի համար մենք կարող ենք \"ավելացնել\" նոր տվյալներ\n",
    "# հների վրա տռանսֆոռմացիաններ կատարելով պտտել, մեծացնել, ֆռցնել։\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,       \n",
    "    width_shift_range=0.1,   \n",
    "    height_shift_range=0.1,  \n",
    "    horizontal_flip=True,    \n",
    ")\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Մոդելին ավելացնենք կոնվ և պօօլ շերտեր որպեսզի\n",
    "# այն կարողանա ավելի բարդ նշաններ քաղի նկարներից\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential([\n",
    "  Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]),\n",
    "  Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "  BatchNormalization(),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "  Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "  BatchNormalization(),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "  Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "  BatchNormalization(),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Flatten(),\n",
    "  Dense(512, activation='relu'),\n",
    "  Dropout(0.5),\n",
    "  Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1342122 (5.12 MB)\n",
      "Trainable params: 1341674 (5.12 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Ոգտագործենք Adamw optimizer-ը և նշանակենք learning-rate ը ու weight_decay-ը որպեսզի սովորելու ընթացքում մոդելը overfit չլնի\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "782/782 [==============================] - 138s 175ms/step - loss: 1.6688 - accuracy: 0.4065 - val_loss: 1.8345 - val_accuracy: 0.4237 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 135s 172ms/step - loss: 1.2247 - accuracy: 0.5679 - val_loss: 1.2490 - val_accuracy: 0.5504 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 133s 170ms/step - loss: 1.0417 - accuracy: 0.6366 - val_loss: 1.0099 - val_accuracy: 0.6454 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 133s 170ms/step - loss: 0.9101 - accuracy: 0.6843 - val_loss: 1.1038 - val_accuracy: 0.6413 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 140s 179ms/step - loss: 0.8193 - accuracy: 0.7196 - val_loss: 0.8691 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 142s 181ms/step - loss: 0.7649 - accuracy: 0.7366 - val_loss: 0.8354 - val_accuracy: 0.7289 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 145s 185ms/step - loss: 0.7153 - accuracy: 0.7545 - val_loss: 0.9006 - val_accuracy: 0.6990 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 144s 184ms/step - loss: 0.6781 - accuracy: 0.7670 - val_loss: 1.0488 - val_accuracy: 0.6620 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.6437 - accuracy: 0.7800 - val_loss: 0.6671 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 139s 177ms/step - loss: 0.6131 - accuracy: 0.7906 - val_loss: 0.7035 - val_accuracy: 0.7630 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.5840 - accuracy: 0.7987 - val_loss: 0.5948 - val_accuracy: 0.8007 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 145s 185ms/step - loss: 0.5714 - accuracy: 0.8030 - val_loss: 0.6989 - val_accuracy: 0.7665 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 147s 188ms/step - loss: 0.5498 - accuracy: 0.8121 - val_loss: 0.6110 - val_accuracy: 0.7978 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 148s 189ms/step - loss: 0.5372 - accuracy: 0.8154 - val_loss: 0.6427 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 156s 199ms/step - loss: 0.4525 - accuracy: 0.8427 - val_loss: 0.5159 - val_accuracy: 0.8299 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 151s 193ms/step - loss: 0.4303 - accuracy: 0.8523 - val_loss: 0.5124 - val_accuracy: 0.8250 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 155s 198ms/step - loss: 0.4228 - accuracy: 0.8552 - val_loss: 0.5534 - val_accuracy: 0.8187 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 0.4156 - accuracy: 0.8576 - val_loss: 0.5459 - val_accuracy: 0.8177 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 139s 177ms/step - loss: 0.4056 - accuracy: 0.8602 - val_loss: 0.6226 - val_accuracy: 0.7927 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 136s 173ms/step - loss: 0.3566 - accuracy: 0.8775 - val_loss: 0.4867 - val_accuracy: 0.8372 - lr: 2.5000e-04\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 137s 176ms/step - loss: 0.3473 - accuracy: 0.8801 - val_loss: 0.4140 - val_accuracy: 0.8618 - lr: 2.5000e-04\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 146s 187ms/step - loss: 0.3425 - accuracy: 0.8828 - val_loss: 0.4169 - val_accuracy: 0.8629 - lr: 2.5000e-04\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.3380 - accuracy: 0.8838 - val_loss: 0.4294 - val_accuracy: 0.8579 - lr: 2.5000e-04\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 134s 171ms/step - loss: 0.3415 - accuracy: 0.8838 - val_loss: 0.4231 - val_accuracy: 0.8588 - lr: 2.5000e-04\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 134s 171ms/step - loss: 0.3111 - accuracy: 0.8943 - val_loss: 0.3935 - val_accuracy: 0.8645 - lr: 1.2500e-04\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 0.3201 - accuracy: 0.8904 - val_loss: 0.4114 - val_accuracy: 0.8616 - lr: 1.2500e-04\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 146s 187ms/step - loss: 0.3253 - accuracy: 0.8896 - val_loss: 0.4104 - val_accuracy: 0.8611 - lr: 1.2500e-04\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 156s 200ms/step - loss: 0.3342 - accuracy: 0.8871 - val_loss: 0.4031 - val_accuracy: 0.8624 - lr: 1.2500e-04\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 164s 210ms/step - loss: 0.3354 - accuracy: 0.8900 - val_loss: 0.4053 - val_accuracy: 0.8644 - lr: 6.2500e-05\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 165s 210ms/step - loss: 0.3501 - accuracy: 0.8857 - val_loss: 0.4199 - val_accuracy: 0.8585 - lr: 6.2500e-05\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 158s 202ms/step - loss: 0.3761 - accuracy: 0.8775 - val_loss: 0.3863 - val_accuracy: 0.8720 - lr: 6.2500e-05\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 145s 186ms/step - loss: 0.3916 - accuracy: 0.8704 - val_loss: 0.4708 - val_accuracy: 0.8411 - lr: 6.2500e-05\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 163s 208ms/step - loss: 0.4065 - accuracy: 0.8652 - val_loss: 0.4223 - val_accuracy: 0.8595 - lr: 6.2500e-05\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 171s 218ms/step - loss: 0.4227 - accuracy: 0.8618 - val_loss: 0.4196 - val_accuracy: 0.8551 - lr: 6.2500e-05\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 148s 189ms/step - loss: 0.4427 - accuracy: 0.8577 - val_loss: 0.4571 - val_accuracy: 0.8467 - lr: 3.1250e-05\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 145s 185ms/step - loss: 0.4863 - accuracy: 0.8451 - val_loss: 0.4928 - val_accuracy: 0.8367 - lr: 3.1250e-05\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 142s 181ms/step - loss: 0.5211 - accuracy: 0.8338 - val_loss: 0.4904 - val_accuracy: 0.8410 - lr: 3.1250e-05\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 139s 177ms/step - loss: 0.5738 - accuracy: 0.8235 - val_loss: 0.6030 - val_accuracy: 0.8043 - lr: 1.5625e-05\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 0.6463 - accuracy: 0.8034 - val_loss: 0.6148 - val_accuracy: 0.8029 - lr: 1.5625e-05\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 148s 189ms/step - loss: 0.7069 - accuracy: 0.7848 - val_loss: 0.6937 - val_accuracy: 0.7703 - lr: 1.5625e-05\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.7930 - accuracy: 0.7647 - val_loss: 0.7606 - val_accuracy: 0.7642 - lr: 7.8125e-06\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 140s 178ms/step - loss: 0.9030 - accuracy: 0.7346 - val_loss: 0.8446 - val_accuracy: 0.7446 - lr: 7.8125e-06\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 145s 186ms/step - loss: 0.9861 - accuracy: 0.7097 - val_loss: 0.9535 - val_accuracy: 0.6986 - lr: 7.8125e-06\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 1.1022 - accuracy: 0.6822 - val_loss: 1.0883 - val_accuracy: 0.6701 - lr: 3.9063e-06\n",
      "Epoch 45/50\n",
      "444/782 [================>.............] - ETA: 1:02 - loss: 1.2155 - accuracy: 0.6520"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Սովորելու ընթացքում իջացնենք lr-ը որպեսզի մոդելը գա օպտիմալ կետի\u001b[39;00m\n\u001b[0;32m      4\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Սովորելու ընթացքում իջացնենք lr-ը որպեսզի մոդելը գա օպտիմալ կետի\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "          validation_data = (x_test,y_test),\n",
    "          epochs=50, validation_split=0.2, callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 133s 168ms/step - loss: 1.6506 - accuracy: 0.4116 - val_loss: 1.2676 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 147s 188ms/step - loss: 1.2155 - accuracy: 0.5705 - val_loss: 1.2420 - val_accuracy: 0.5853 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 142s 181ms/step - loss: 1.0320 - accuracy: 0.6387 - val_loss: 0.9613 - val_accuracy: 0.6660 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 140s 180ms/step - loss: 0.9125 - accuracy: 0.6830 - val_loss: 1.0464 - val_accuracy: 0.6670 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 143s 183ms/step - loss: 0.8273 - accuracy: 0.7154 - val_loss: 0.9545 - val_accuracy: 0.6686 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 147s 188ms/step - loss: 0.7610 - accuracy: 0.7379 - val_loss: 0.8812 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 142s 181ms/step - loss: 0.7043 - accuracy: 0.7593 - val_loss: 0.7845 - val_accuracy: 0.7350 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 0.6615 - accuracy: 0.7737 - val_loss: 0.7944 - val_accuracy: 0.7386 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 141s 180ms/step - loss: 0.6419 - accuracy: 0.7795 - val_loss: 0.8209 - val_accuracy: 0.7218 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.6133 - accuracy: 0.7902 - val_loss: 0.7286 - val_accuracy: 0.7611 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 140s 179ms/step - loss: 0.5860 - accuracy: 0.7997 - val_loss: 0.8893 - val_accuracy: 0.7276 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 141s 180ms/step - loss: 0.5614 - accuracy: 0.8095 - val_loss: 0.7249 - val_accuracy: 0.7586 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 144s 184ms/step - loss: 0.5488 - accuracy: 0.8120 - val_loss: 0.6845 - val_accuracy: 0.7759 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 155s 199ms/step - loss: 0.5338 - accuracy: 0.8193 - val_loss: 0.5752 - val_accuracy: 0.8021 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 153s 195ms/step - loss: 0.5189 - accuracy: 0.8240 - val_loss: 0.7713 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 156s 200ms/step - loss: 0.5118 - accuracy: 0.8233 - val_loss: 0.5812 - val_accuracy: 0.8024 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 157s 200ms/step - loss: 0.4942 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7893 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 167s 214ms/step - loss: 0.4175 - accuracy: 0.8556 - val_loss: 0.5016 - val_accuracy: 0.8319 - lr: 5.0000e-04\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 160s 205ms/step - loss: 0.4006 - accuracy: 0.8621 - val_loss: 0.4934 - val_accuracy: 0.8383 - lr: 5.0000e-04\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 161s 206ms/step - loss: 0.3851 - accuracy: 0.8665 - val_loss: 0.6896 - val_accuracy: 0.7724 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 0.3879 - accuracy: 0.8667 - val_loss: 0.4237 - val_accuracy: 0.8534 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 128s 163ms/step - loss: 0.3779 - accuracy: 0.8698 - val_loss: 0.5688 - val_accuracy: 0.8075 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 131s 168ms/step - loss: 0.3761 - accuracy: 0.8700 - val_loss: 0.7524 - val_accuracy: 0.7834 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 131s 167ms/step - loss: 0.3692 - accuracy: 0.8724 - val_loss: 0.5011 - val_accuracy: 0.8296 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 131s 168ms/step - loss: 0.3205 - accuracy: 0.8895 - val_loss: 0.3814 - val_accuracy: 0.8713 - lr: 2.5000e-04\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 128s 163ms/step - loss: 0.3129 - accuracy: 0.8918 - val_loss: 0.4137 - val_accuracy: 0.8591 - lr: 2.5000e-04\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 129s 164ms/step - loss: 0.3120 - accuracy: 0.8942 - val_loss: 0.4639 - val_accuracy: 0.8440 - lr: 2.5000e-04\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 127s 162ms/step - loss: 0.3131 - accuracy: 0.8924 - val_loss: 0.4910 - val_accuracy: 0.8323 - lr: 2.5000e-04\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 127s 162ms/step - loss: 0.2905 - accuracy: 0.9001 - val_loss: 0.4663 - val_accuracy: 0.8482 - lr: 1.2500e-04\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 127s 162ms/step - loss: 0.2905 - accuracy: 0.9028 - val_loss: 0.3501 - val_accuracy: 0.8834 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20d39f89e40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,       \n",
    "    width_shift_range=0.1,   \n",
    "    height_shift_range=0.1,  \n",
    "    horizontal_flip=True,    \n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential([\n",
    "  Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]),\n",
    "  Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "  BatchNormalization(),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "  Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "  BatchNormalization(),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "  Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "  BatchNormalization(),\n",
    "  MaxPooling2D(2, 2),\n",
    "  \n",
    "  Flatten(),\n",
    "  Dense(512, activation='relu'),\n",
    "  Dropout(0.5),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-4)\n",
    "\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "          validation_data = (x_test,y_test),\n",
    "          epochs=30, validation_split=0.2, callbacks=[reduce_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3501017689704895 / Test accuracy: 0.883400022983551\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "model.save('newModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.3035 - accuracy: 0.8977 - val_loss: 0.4316 - val_accuracy: 0.8529 - lr: 1.2500e-04\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.3090 - accuracy: 0.8967 - val_loss: 0.3753 - val_accuracy: 0.8709 - lr: 1.2500e-04\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 134s 171ms/step - loss: 0.3207 - accuracy: 0.8919 - val_loss: 0.3578 - val_accuracy: 0.8784 - lr: 1.2500e-04\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 148s 190ms/step - loss: 0.3263 - accuracy: 0.8899 - val_loss: 0.3890 - val_accuracy: 0.8692 - lr: 1.2500e-04\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 153s 195ms/step - loss: 0.3307 - accuracy: 0.8899 - val_loss: 0.4242 - val_accuracy: 0.8549 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20d3a86ff10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "          validation_data = (x_test,y_test),\n",
    "          epochs=5, validation_split=0.2, callbacks=[reduce_lr])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
